{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from secret import OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In the realm of code where wonders unfold,\\nLies a concept both simple and bold,\\nRecursion, a loop with a twist,\\nA mystical function that should not be missed.\\n\\nIt starts with a task, a problem to solve,\\nA function that calls itself, how it evolves,\\nLike a mirror reflecting its own image,\\nIt dives deeper, like a river in a passage.\\n\\nInfinite loops may bring dismay,\\nBut recursion knows how to play,\\nBreaking down problems into smaller parts,\\nUnraveling mysteries, connecting hearts.\\n\\nEach recursive call a journey profound,\\nTraversing through layers, profound,\\nUntil the base case brings it back,\\nReturning triumphantly on its track.\\n\\nA dance of elegance, a symphony of code,\\nRecursion sweeps through, in an elegant mode,\\nLike a dream within a dream, it goes on,\\nIn the world of programming, its beauty shone.\\n\\nSo fear not the recursive abyss,\\nFor in its depths lies pure bliss,\\nA concept so magical, so divine,\\nIn the art of programming, it will shine.'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a poetic assistant, skilled in explaining complex programming concepts with creative flair.\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Compose a poem that explains the concept of recursion in programming.\",\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "completion.choices[0].message.content\n",
    "# print(completion.choices[0].message)\n",
    "# response = client.completions.create( # legacy here.\n",
    "#   model=\"gpt-3.5-turbo-instruct\",\n",
    "#   prompt=\"Write a tagline for an ice cream shop.\"\n",
    "# )\n",
    "# config.get(\"model\", \"gpt-4-turbo-preview\"),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import gc\n",
    "# gc.collect() # for cleaning out the memory\n",
    "\n",
    "class Debugger:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use graph extractor to get the graph. GraphExtractor\n",
    "\n",
    "\n",
    "# async def run_extract_entities -> this function show us how the entities are extracted\n",
    "# async def run_extract_entities(\n",
    "#     llm: CompletionLLM,\n",
    "#     docs: list[Document],\n",
    "#     entity_types: EntityTypes,\n",
    "#     reporter: VerbCallbacks | None,\n",
    "#     args: StrategyConfig,\n",
    "# ) -> EntityExtractionResult\n",
    "from dataclasses import dataclass\n",
    "from abc import ABC, abstractmethod\n",
    "from typing import Any, Callable, Collection, Iterable, Literal, cast\n",
    "import pandas as pd\n",
    "import tiktoken\n",
    "\n",
    "LengthFn = Callable[[str], int]\n",
    "\n",
    "\n",
    "class TextSplitter(ABC):\n",
    "    \"\"\"Text splitter class definition.\"\"\"\n",
    "\n",
    "    _chunk_size: int\n",
    "    _chunk_overlap: int\n",
    "    _length_function: LengthFn\n",
    "    _keep_separator: bool\n",
    "    _add_start_index: bool\n",
    "    _strip_whitespace: bool\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        # based on text-ada-002-embedding max input buffer length\n",
    "        # https://platform.openai.com/docs/guides/embeddings/second-generation-models\n",
    "        chunk_size: int = 8191,\n",
    "        chunk_overlap: int = 100,\n",
    "        length_function: LengthFn = len,\n",
    "        keep_separator: bool = False,\n",
    "        add_start_index: bool = False,\n",
    "        strip_whitespace: bool = True,\n",
    "    ):\n",
    "        \"\"\"Init method definition.\"\"\"\n",
    "        self._chunk_size = chunk_size\n",
    "        self._chunk_overlap = chunk_overlap\n",
    "        self._length_function = length_function\n",
    "        self._keep_separator = keep_separator\n",
    "        self._add_start_index = add_start_index\n",
    "        self._strip_whitespace = strip_whitespace\n",
    "\n",
    "    @abstractmethod\n",
    "    def split_text(self, text: str | list[str]) -> Iterable[str]:\n",
    "        \"\"\"Split text method definition.\"\"\"\n",
    "\n",
    "\n",
    "EncodedText = list[int]\n",
    "DecodeFn = Callable[[EncodedText], str]\n",
    "EncodeFn = Callable[[str], EncodedText]\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class Tokenizer:\n",
    "    \"\"\"Tokenizer data class.\"\"\"\n",
    "\n",
    "    chunk_overlap: int\n",
    "    \"\"\"Overlap in tokens between chunks\"\"\"\n",
    "    tokens_per_chunk: int\n",
    "    \"\"\"Maximum number of tokens per chunk\"\"\"\n",
    "    decode: DecodeFn\n",
    "    \"\"\" Function to decode a list of token ids to a string\"\"\"\n",
    "    encode: EncodeFn\n",
    "    \"\"\" Function to encode a string to a list of token ids\"\"\"\n",
    "\n",
    "\n",
    "class TokenTextSplitter(TextSplitter):\n",
    "    \"\"\"Token text splitter class definition.\"\"\"\n",
    "\n",
    "    _allowed_special: Literal[\"all\"] | set[str]\n",
    "    _disallowed_special: Literal[\"all\"] | Collection[str]\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        encoding_name: str = \"cl100k_base\",\n",
    "        model_name: str | None = None,\n",
    "        allowed_special: Literal[\"all\"] | set[str] | None = None,\n",
    "        disallowed_special: Literal[\"all\"] | Collection[str] = \"all\",\n",
    "        **kwargs: Any,\n",
    "    ):\n",
    "        \"\"\"Init method definition.\"\"\"\n",
    "        super().__init__(**kwargs)\n",
    "        if model_name is not None:\n",
    "            try:\n",
    "                enc = tiktoken.encoding_for_model(model_name)\n",
    "            except KeyError:\n",
    "                enc = tiktoken.get_encoding(encoding_name)\n",
    "        else:\n",
    "            enc = tiktoken.get_encoding(encoding_name)\n",
    "        self._tokenizer = enc\n",
    "        self._allowed_special = allowed_special or set()\n",
    "        self._disallowed_special = disallowed_special\n",
    "\n",
    "    def encode(self, text: str) -> list[int]:\n",
    "        \"\"\"Encode the given text into an int-vector.\"\"\"\n",
    "        return self._tokenizer.encode(\n",
    "            text,\n",
    "            allowed_special=self._allowed_special,\n",
    "            disallowed_special=self._disallowed_special,\n",
    "        )\n",
    "\n",
    "    def num_tokens(self, text: str) -> int:\n",
    "        \"\"\"Return the number of tokens in a string.\"\"\"\n",
    "        return len(self.encode(text))\n",
    "\n",
    "    def split_text(self, text: str | list[str]) -> list[str]:\n",
    "        \"\"\"Split text method.\"\"\"\n",
    "        if cast(bool, pd.isna(text)) or text == \"\":\n",
    "            return []\n",
    "        if isinstance(text, list):\n",
    "            text = \" \".join(text)\n",
    "        if not isinstance(text, str):\n",
    "            msg = f\"Attempting to split a non-string value, actual is {type(text)}\"\n",
    "            raise TypeError(msg)\n",
    "\n",
    "        tokenizer = Tokenizer(\n",
    "            chunk_overlap=self._chunk_overlap,\n",
    "            tokens_per_chunk=self._chunk_size,\n",
    "            decode=self._tokenizer.decode,\n",
    "            encode=lambda text: self.encode(text),\n",
    "        )\n",
    "\n",
    "        return split_text_on_tokens(text=text, tokenizer=tokenizer)\n",
    "\n",
    "\n",
    "def split_text_on_tokens(*, text: str, tokenizer: Tokenizer) -> list[str]:\n",
    "    \"\"\"Split incoming text and return chunks using tokenizer.\"\"\"\n",
    "    splits: list[str] = []\n",
    "    input_ids = tokenizer.encode(text)\n",
    "    start_idx = 0\n",
    "    cur_idx = min(start_idx + tokenizer.tokens_per_chunk, len(input_ids))\n",
    "    chunk_ids = input_ids[start_idx:cur_idx]\n",
    "    while start_idx < len(input_ids):\n",
    "        splits.append(tokenizer.decode(chunk_ids))\n",
    "        start_idx += tokenizer.tokens_per_chunk - tokenizer.chunk_overlap\n",
    "        cur_idx = min(start_idx + tokenizer.tokens_per_chunk, len(input_ids))\n",
    "        chunk_ids = input_ids[start_idx:cur_idx]\n",
    "    return splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_text_splitter(\n",
    "    chunk_size: int, chunk_overlap: int, encoding_name: str\n",
    ") -> TextSplitter:\n",
    "    \"\"\"Create a text splitter for the extraction chain.\n",
    "\n",
    "    Args:\n",
    "        - prechunked - Whether the text is already chunked\n",
    "        - chunk_size - The size of each chunk\n",
    "        - chunk_overlap - The overlap between chunks\n",
    "        - encoding_name - The name of the encoding to use\n",
    "    Returns:\n",
    "        - output - A text splitter\n",
    "    \"\"\"\n",
    "\n",
    "    return TokenTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap,\n",
    "        encoding_name=encoding_name,\n",
    "    )\n",
    "\n",
    "\n",
    "CHUNK_SIZE = 1200\n",
    "CHUNK_OVERLAP = 100\n",
    "\n",
    "text_splitter = create_text_splitter(CHUNK_SIZE, CHUNK_OVERLAP, \"cl100k_base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# async def run_extract_entities(  <- this is important as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "GRAPH_EXTRACTION_PROMPT = \"\"\"\n",
    "-Goal-\n",
    "Given a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\n",
    "\n",
    "-Steps-\n",
    "1. Identify all entities. For each identified entity, extract the following information:\n",
    "- entity_name: Name of the entity, capitalized\n",
    "- entity_type: One of the following types: [{entity_types}]\n",
    "- entity_description: Comprehensive description of the entity's attributes and activities\n",
    "Format each entity as (\"entity\"{tuple_delimiter}<entity_name>{tuple_delimiter}<entity_type>{tuple_delimiter}<entity_description>\n",
    "\n",
    "2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\n",
    "For each pair of related entities, extract the following information:\n",
    "- source_entity: name of the source entity, as identified in step 1\n",
    "- target_entity: name of the target entity, as identified in step 1\n",
    "- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n",
    "- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity\n",
    " Format each relationship as (\"relationship\"{tuple_delimiter}<source_entity>{tuple_delimiter}<target_entity>{tuple_delimiter}<relationship_description>{tuple_delimiter}<relationship_strength>)\n",
    "\n",
    "3. Return output in English as a single list of all the entities and relationships identified in steps 1 and 2. Use **{record_delimiter}** as the list delimiter.\n",
    "\n",
    "4. When finished, output {completion_delimiter}\n",
    "\n",
    "######################\n",
    "-Examples-\n",
    "######################\n",
    "Example 1:\n",
    "\n",
    "Entity_types: [person, technology, mission, organization, location]\n",
    "Text:\n",
    "while Alex clenched his jaw, the buzz of frustration dull against the backdrop of Taylor's authoritarian certainty. It was this competitive undercurrent that kept him alert, the sense that his and Jordan's shared commitment to discovery was an unspoken rebellion against Cruz's narrowing vision of control and order.\n",
    "\n",
    "Then Taylor did something unexpected. They paused beside Jordan and, for a moment, observed the device with something akin to reverence. “If this tech can be understood...\" Taylor said, their voice quieter, \"It could change the game for us. For all of us.”\n",
    "\n",
    "The underlying dismissal earlier seemed to falter, replaced by a glimpse of reluctant respect for the gravity of what lay in their hands. Jordan looked up, and for a fleeting heartbeat, their eyes locked with Taylor's, a wordless clash of wills softening into an uneasy truce.\n",
    "\n",
    "It was a small transformation, barely perceptible, but one that Alex noted with an inward nod. They had all been brought here by different paths\n",
    "################\n",
    "Output:\n",
    "(\"entity\"{tuple_delimiter}\"Alex\"{tuple_delimiter}\"person\"{tuple_delimiter}\"Alex is a character who experiences frustration and is observant of the dynamics among other characters.\"){record_delimiter}\n",
    "(\"entity\"{tuple_delimiter}\"Taylor\"{tuple_delimiter}\"person\"{tuple_delimiter}\"Taylor is portrayed with authoritarian certainty and shows a moment of reverence towards a device, indicating a change in perspective.\"){record_delimiter}\n",
    "(\"entity\"{tuple_delimiter}\"Jordan\"{tuple_delimiter}\"person\"{tuple_delimiter}\"Jordan shares a commitment to discovery and has a significant interaction with Taylor regarding a device.\"){record_delimiter}\n",
    "(\"entity\"{tuple_delimiter}\"Cruz\"{tuple_delimiter}\"person\"{tuple_delimiter}\"Cruz is associated with a vision of control and order, influencing the dynamics among other characters.\"){record_delimiter}\n",
    "(\"entity\"{tuple_delimiter}\"The Device\"{tuple_delimiter}\"technology\"{tuple_delimiter}\"The Device is central to the story, with potential game-changing implications, and is revered by Taylor.\"){record_delimiter}\n",
    "(\"relationship\"{tuple_delimiter}\"Alex\"{tuple_delimiter}\"Taylor\"{tuple_delimiter}\"Alex is affected by Taylor's authoritarian certainty and observes changes in Taylor's attitude towards the device.\"{tuple_delimiter}7){record_delimiter}\n",
    "(\"relationship\"{tuple_delimiter}\"Alex\"{tuple_delimiter}\"Jordan\"{tuple_delimiter}\"Alex and Jordan share a commitment to discovery, which contrasts with Cruz's vision.\"{tuple_delimiter}6){record_delimiter}\n",
    "(\"relationship\"{tuple_delimiter}\"Taylor\"{tuple_delimiter}\"Jordan\"{tuple_delimiter}\"Taylor and Jordan interact directly regarding the device, leading to a moment of mutual respect and an uneasy truce.\"{tuple_delimiter}8){record_delimiter}\n",
    "(\"relationship\"{tuple_delimiter}\"Jordan\"{tuple_delimiter}\"Cruz\"{tuple_delimiter}\"Jordan's commitment to discovery is in rebellion against Cruz's vision of control and order.\"{tuple_delimiter}5){record_delimiter}\n",
    "(\"relationship\"{tuple_delimiter}\"Taylor\"{tuple_delimiter}\"The Device\"{tuple_delimiter}\"Taylor shows reverence towards the device, indicating its importance and potential impact.\"{tuple_delimiter}9){completion_delimiter}\n",
    "#############################\n",
    "Example 2:\n",
    "\n",
    "Entity_types: [person, technology, mission, organization, location]\n",
    "Text:\n",
    "They were no longer mere operatives; they had become guardians of a threshold, keepers of a message from a realm beyond stars and stripes. This elevation in their mission could not be shackled by regulations and established protocols—it demanded a new perspective, a new resolve.\n",
    "\n",
    "Tension threaded through the dialogue of beeps and static as communications with Washington buzzed in the background. The team stood, a portentous air enveloping them. It was clear that the decisions they made in the ensuing hours could redefine humanity's place in the cosmos or condemn them to ignorance and potential peril.\n",
    "\n",
    "Their connection to the stars solidified, the group moved to address the crystallizing warning, shifting from passive recipients to active participants. Mercer's latter instincts gained precedence— the team's mandate had evolved, no longer solely to observe and report but to interact and prepare. A metamorphosis had begun, and Operation: Dulce hummed with the newfound frequency of their daring, a tone set not by the earthly\n",
    "#############\n",
    "Output:\n",
    "(\"entity\"{tuple_delimiter}\"Washington\"{tuple_delimiter}\"location\"{tuple_delimiter}\"Washington is a location where communications are being received, indicating its importance in the decision-making process.\"){record_delimiter}\n",
    "(\"entity\"{tuple_delimiter}\"Operation: Dulce\"{tuple_delimiter}\"mission\"{tuple_delimiter}\"Operation: Dulce is described as a mission that has evolved to interact and prepare, indicating a significant shift in objectives and activities.\"){record_delimiter}\n",
    "(\"entity\"{tuple_delimiter}\"The team\"{tuple_delimiter}\"organization\"{tuple_delimiter}\"The team is portrayed as a group of individuals who have transitioned from passive observers to active participants in a mission, showing a dynamic change in their role.\"){record_delimiter}\n",
    "(\"relationship\"{tuple_delimiter}\"The team\"{tuple_delimiter}\"Washington\"{tuple_delimiter}\"The team receives communications from Washington, which influences their decision-making process.\"{tuple_delimiter}7){record_delimiter}\n",
    "(\"relationship\"{tuple_delimiter}\"The team\"{tuple_delimiter}\"Operation: Dulce\"{tuple_delimiter}\"The team is directly involved in Operation: Dulce, executing its evolved objectives and activities.\"{tuple_delimiter}9){completion_delimiter}\n",
    "#############################\n",
    "Example 3:\n",
    "\n",
    "Entity_types: [person, role, technology, organization, event, location, concept]\n",
    "Text:\n",
    "their voice slicing through the buzz of activity. \"Control may be an illusion when facing an intelligence that literally writes its own rules,\" they stated stoically, casting a watchful eye over the flurry of data.\n",
    "\n",
    "\"It's like it's learning to communicate,\" offered Sam Rivera from a nearby interface, their youthful energy boding a mix of awe and anxiety. \"This gives talking to strangers' a whole new meaning.\"\n",
    "\n",
    "Alex surveyed his team—each face a study in concentration, determination, and not a small measure of trepidation. \"This might well be our first contact,\" he acknowledged, \"And we need to be ready for whatever answers back.\"\n",
    "\n",
    "Together, they stood on the edge of the unknown, forging humanity's response to a message from the heavens. The ensuing silence was palpable—a collective introspection about their role in this grand cosmic play, one that could rewrite human history.\n",
    "\n",
    "The encrypted dialogue continued to unfold, its intricate patterns showing an almost uncanny anticipation\n",
    "#############\n",
    "Output:\n",
    "(\"entity\"{tuple_delimiter}\"Sam Rivera\"{tuple_delimiter}\"person\"{tuple_delimiter}\"Sam Rivera is a member of a team working on communicating with an unknown intelligence, showing a mix of awe and anxiety.\"){record_delimiter}\n",
    "(\"entity\"{tuple_delimiter}\"Alex\"{tuple_delimiter}\"person\"{tuple_delimiter}\"Alex is the leader of a team attempting first contact with an unknown intelligence, acknowledging the significance of their task.\"){record_delimiter}\n",
    "(\"entity\"{tuple_delimiter}\"Control\"{tuple_delimiter}\"concept\"{tuple_delimiter}\"Control refers to the ability to manage or govern, which is challenged by an intelligence that writes its own rules.\"){record_delimiter}\n",
    "(\"entity\"{tuple_delimiter}\"Intelligence\"{tuple_delimiter}\"concept\"{tuple_delimiter}\"Intelligence here refers to an unknown entity capable of writing its own rules and learning to communicate.\"){record_delimiter}\n",
    "(\"entity\"{tuple_delimiter}\"First Contact\"{tuple_delimiter}\"event\"{tuple_delimiter}\"First Contact is the potential initial communication between humanity and an unknown intelligence.\"){record_delimiter}\n",
    "(\"entity\"{tuple_delimiter}\"Humanity's Response\"{tuple_delimiter}\"event\"{tuple_delimiter}\"Humanity's Response is the collective action taken by Alex's team in response to a message from an unknown intelligence.\"){record_delimiter}\n",
    "(\"relationship\"{tuple_delimiter}\"Sam Rivera\"{tuple_delimiter}\"Intelligence\"{tuple_delimiter}\"Sam Rivera is directly involved in the process of learning to communicate with the unknown intelligence.\"{tuple_delimiter}9){record_delimiter}\n",
    "(\"relationship\"{tuple_delimiter}\"Alex\"{tuple_delimiter}\"First Contact\"{tuple_delimiter}\"Alex leads the team that might be making the First Contact with the unknown intelligence.\"{tuple_delimiter}10){record_delimiter}\n",
    "(\"relationship\"{tuple_delimiter}\"Alex\"{tuple_delimiter}\"Humanity's Response\"{tuple_delimiter}\"Alex and his team are the key figures in Humanity's Response to the unknown intelligence.\"{tuple_delimiter}8){record_delimiter}\n",
    "(\"relationship\"{tuple_delimiter}\"Control\"{tuple_delimiter}\"Intelligence\"{tuple_delimiter}\"The concept of Control is challenged by the Intelligence that writes its own rules.\"{tuple_delimiter}7){completion_delimiter}\n",
    "#############################\n",
    "-Real Data-\n",
    "######################\n",
    "Entity_types: {entity_types}\n",
    "Text: {input_text}\n",
    "######################\n",
    "Output:\"\"\"\n",
    "\n",
    "CONTINUE_PROMPT = \"MANY entities were missed in the last extraction.  Add them below using the same format:\\n\"\n",
    "LOOP_PROMPT = \"It appears some entities may have still been missed.  Answer YES | NO if there are still entities that need to be added.\\n\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A,B'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\",\".join([\"A\", \"B\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List\n",
    "from openai import OpenAI\n",
    "import openai\n",
    "\n",
    "\n",
    "openai.api_key = OPENAI_API_KEY\n",
    "\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "# ###### Try both API\n",
    "# completion = client.chat.completions.create(\n",
    "#     model=\"gpt-3.5-turbo\",\n",
    "#     messages=[\n",
    "#         {\n",
    "#             \"role\": \"system\",\n",
    "#             \"content\": \"You are a poetic assistant, skilled in explaining complex programming concepts with creative flair.\",\n",
    "#         },\n",
    "#         {\n",
    "#             \"role\": \"user\",\n",
    "#             \"content\": \"Compose a poem that explains the concept of recursion in programming.\",\n",
    "#         },\n",
    "#     ],\n",
    "# )\n",
    "\n",
    "from tenacity import (\n",
    "    retry,\n",
    "    stop_after_attempt,\n",
    "    wait_random_exponential,\n",
    "    retry_if_exception_type,\n",
    ")  # for exponential backoff\n",
    "\n",
    "\n",
    "@retry(\n",
    "    retry=retry_if_exception_type(\n",
    "        (\n",
    "            openai.APIError,\n",
    "            openai.APIConnectionError,\n",
    "            openai.RateLimitError,\n",
    "            openai.InternalServerError,\n",
    "            openai.Timeout,\n",
    "        )\n",
    "    ),\n",
    "    wait=wait_random_exponential(multiplier=1, max=60),\n",
    "    stop=stop_after_attempt(10),\n",
    ")\n",
    "def chat_completion_with_backoff(**kwargs):\n",
    "    return openai.chat.completions.create(**kwargs)\n",
    "\n",
    "    # prompt_variables = {\n",
    "    #     **prompt_variables,\n",
    "    #     self._tuple_delimiter_key: prompt_variables.get(self._tuple_delimiter_key)\n",
    "    #     or DEFAULT_TUPLE_DELIMITER,\n",
    "    #     self._record_delimiter_key: prompt_variables.get(self._record_delimiter_key)\n",
    "    #     or DEFAULT_RECORD_DELIMITER,\n",
    "    #     self._completion_delimiter_key: prompt_variables.get(\n",
    "    #         self._completion_delimiter_key\n",
    "    #     )\n",
    "    #     or DEFAULT_COMPLETION_DELIMITER,\n",
    "    #     self._entity_types_key: \",\".join(\n",
    "    #         prompt_variables[self._entity_types_key] or DEFAULT_ENTITY_TYPES\n",
    "    #     ),\n",
    "    # }\n",
    "\n",
    "\n",
    "def perform_variable_replacements(\n",
    "    input: str, history: list[dict], variables: dict | None\n",
    ") -> str:\n",
    "    \"\"\"Perform variable replacements on the input string and in a chat log.\"\"\"\n",
    "    result = input\n",
    "\n",
    "    def replace_all(input: str) -> str:\n",
    "        result = input\n",
    "        if variables:\n",
    "            for entry in variables:\n",
    "                result = result.replace(f\"{{{entry}}}\", variables[entry])\n",
    "        return result\n",
    "\n",
    "    result = replace_all(result)\n",
    "    for i in range(len(history)):\n",
    "        entry = history[i]\n",
    "        if entry.get(\"role\") == \"system\":\n",
    "            history[i][\"content\"] = replace_all(entry.get(\"content\") or \"\")\n",
    "\n",
    "    return result\n",
    "\n",
    "    # prompt_variables = {\n",
    "    #     **prompt_variables,\n",
    "    #     self._tuple_delimiter_key: prompt_variables.get(self._tuple_delimiter_key)\n",
    "    #     or DEFAULT_TUPLE_DELIMITER,\n",
    "    #     self._record_delimiter_key: prompt_variables.get(self._record_delimiter_key)\n",
    "    #     or DEFAULT_RECORD_DELIMITER,\n",
    "    #     self._completion_delimiter_key: prompt_variables.get(\n",
    "    #         self._completion_delimiter_key\n",
    "    #     )\n",
    "    #     or DEFAULT_COMPLETION_DELIMITER,\n",
    "    #     self._entity_types_key: \",\".join(\n",
    "    #         prompt_variables[self._entity_types_key] or DEFAULT_ENTITY_TYPES\n",
    "    #     ),\n",
    "    # }\n",
    "\n",
    "\n",
    "def execute_llm(\n",
    "    extraction_prompt,\n",
    "    variables: Dict | None = None,\n",
    "    history: List | None = None,\n",
    "):\n",
    "    input = perform_variable_replacements(extraction_prompt, history, variables)\n",
    "    messages = []\n",
    "    if history:\n",
    "        messages.extend(history)\n",
    "\n",
    "    messages.append(\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": input,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    response = chat_completion_with_backoff(\n",
    "        **{\n",
    "            \"model\": \"gpt-3.5-turbo\",\n",
    "            \"messages\": messages,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    output = response.choices[0].message.content\n",
    "\n",
    "    history = [*history, {\"role\": \"system\", \"content\": output}]\n",
    "\n",
    "    return output, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "extraction_prompt = GRAPH_EXTRACTION_PROMPT\n",
    "max_gleanings = 1\n",
    "join_descriptions = True\n",
    "input_text_key = \"input_text\"\n",
    "tuple_delimiter_key = \"tuple_delimiter\"\n",
    "record_delimiter_key = \"record_delimiter\"\n",
    "completion_delimiter_key = \"completion_delimiter\"\n",
    "entity_types_key = \"entity_types\"\n",
    "# llm = load_llm(\"entity_extraction\", llm_type, reporter, pipeline_cache, llm_config)\n",
    "\n",
    "\n",
    "def process_document(\n",
    "    extraction_prompt: str, text: str, prompt_variables: dict[str, str]\n",
    ") -> str:\n",
    "\n",
    "    #  execute_llm(prompt, variables, history: List | None):\n",
    "\n",
    "    results, history = execute_llm(\n",
    "        extraction_prompt=extraction_prompt,\n",
    "        variables={\n",
    "            **prompt_variables,\n",
    "            input_text_key: text,\n",
    "        },\n",
    "        history=[],\n",
    "    )\n",
    "\n",
    "    results = results or \"\"\n",
    "    # Repeat to ensure we maximize entity count\n",
    "\n",
    "    for i in range(max_gleanings):\n",
    "\n",
    "        glean_response, history = execute_llm(\n",
    "            CONTINUE_PROMPT,\n",
    "            # name=f\"extract-continuation-{i}\",\n",
    "            history=history or [],\n",
    "        )\n",
    "\n",
    "        results += glean_response or \"\"\n",
    "\n",
    "        # if this is the final glean, don't bother updating the continuation flag\n",
    "        if i >= max_gleanings - 1:\n",
    "            break\n",
    "\n",
    "        continuation = execute_llm(\n",
    "            LOOP_PROMPT,\n",
    "            # name=f\"extract-loopcheck-{i}\",\n",
    "            history=history or [],\n",
    "        )\n",
    "\n",
    "        if continuation.output != \"YES\":\n",
    "            break\n",
    "\n",
    "\n",
    "    Debugger.history = history\n",
    "    Debugger.results = results\n",
    "    # raise StopIteration()\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "import numbers\n",
    "import html\n",
    "import re\n",
    "import networkx as nx\n",
    "\n",
    "\n",
    "def clean_str(input: Any) -> str:\n",
    "    \"\"\"Clean an input string by removing HTML escapes, control characters, and other unwanted characters.\"\"\"\n",
    "    # If we get non-string input, just give it back\n",
    "    if not isinstance(input, str):\n",
    "        return input\n",
    "\n",
    "    result = html.unescape(input.strip())\n",
    "    # https://stackoverflow.com/questions/4324790/removing-control-characters-from-a-string-in-python\n",
    "    return re.sub(r\"[\\x00-\\x1f\\x7f-\\x9f]\", \"\", result)\n",
    "\n",
    "\n",
    "def unpack_descriptions(data) -> list[str]:\n",
    "    value = data.get(\"description\", None)\n",
    "    return [] if value is None else value.split(\"\\n\")\n",
    "\n",
    "\n",
    "def _unpack_source_ids(data) -> list[str]:\n",
    "    value = data.get(\"source_id\", None)\n",
    "    return [] if value is None else value.split(\", \")\n",
    "\n",
    "\n",
    "def process_results(\n",
    "    results: dict[int, str],\n",
    "    tuple_delimiter: str,\n",
    "    record_delimiter: str,\n",
    ") -> nx.Graph:\n",
    "\n",
    "    graph = nx.Graph()\n",
    "\n",
    "    for source_doc_id, extracted_data in results.items():\n",
    "\n",
    "        records = [r.strip() for r in extracted_data.split(record_delimiter)]\n",
    "\n",
    "        for record in records:\n",
    "            record = re.sub(r\"^\\(|\\)$\", \"\", record.strip())\n",
    "            record_attributes = record.split(tuple_delimiter)\n",
    "\n",
    "            if record_attributes[0] == '\"entity\"' and len(record_attributes) >= 4:\n",
    "\n",
    "                # add this record as a node in the G\n",
    "                entity_name = clean_str(record_attributes[1].upper())\n",
    "\n",
    "                entity_type = clean_str(record_attributes[2].upper())\n",
    "\n",
    "                entity_description = clean_str(record_attributes[3])\n",
    "\n",
    "                if entity_name in graph.nodes():\n",
    "                    node = graph.nodes[entity_name]\n",
    "\n",
    "                    if join_descriptions:\n",
    "                        node[\"description\"] = \"\\n\".join(\n",
    "                            list(\n",
    "                                {\n",
    "                                    *unpack_descriptions(node),\n",
    "                                    entity_description,\n",
    "                                }\n",
    "                            )\n",
    "                        )\n",
    "\n",
    "                    else:\n",
    "                        if len(entity_description) > len(node[\"description\"]):\n",
    "                            node[\"description\"] = entity_description\n",
    "\n",
    "                    node[\"source_id\"] = \", \".join(\n",
    "                        list(\n",
    "                            {\n",
    "                                *_unpack_source_ids(node),\n",
    "                                str(source_doc_id),\n",
    "                            }\n",
    "                        )\n",
    "                    )\n",
    "\n",
    "                    node[\"entity_type\"] = (\n",
    "                        entity_type if entity_type != \"\" else node[\"entity_type\"]\n",
    "                    )\n",
    "\n",
    "                else:\n",
    "\n",
    "                    graph.add_node(\n",
    "                        entity_name,\n",
    "                        type=entity_type,\n",
    "                        description=entity_description,\n",
    "                        source_id=str(source_doc_id),\n",
    "                    )\n",
    "\n",
    "            if record_attributes[0] == '\"relationship\"' and len(record_attributes) >= 5:\n",
    "\n",
    "                # add this record as edge\n",
    "\n",
    "                source = clean_str(record_attributes[1].upper())\n",
    "\n",
    "                target = clean_str(record_attributes[2].upper())\n",
    "\n",
    "                edge_description = clean_str(record_attributes[3])\n",
    "\n",
    "                edge_source_id = clean_str(str(source_doc_id))\n",
    "\n",
    "                weight = (\n",
    "                    float(record_attributes[-1])\n",
    "                    if isinstance(record_attributes[-1], numbers.Number)\n",
    "                    else 1.0\n",
    "                )\n",
    "\n",
    "                if source not in graph.nodes():\n",
    "\n",
    "                    graph.add_node(\n",
    "                        source,\n",
    "                        type=\"\",\n",
    "                        description=\"\",\n",
    "                        source_id=edge_source_id,\n",
    "                    )\n",
    "\n",
    "                if target not in graph.nodes():\n",
    "\n",
    "                    graph.add_node(\n",
    "                        target,\n",
    "                        type=\"\",\n",
    "                        description=\"\",\n",
    "                        source_id=edge_source_id,\n",
    "                    )\n",
    "\n",
    "                if graph.has_edge(source, target):\n",
    "\n",
    "                    edge_data = graph.get_edge_data(source, target)\n",
    "\n",
    "                    if edge_data is not None:\n",
    "\n",
    "                        weight += edge_data[\"weight\"]\n",
    "\n",
    "                        if join_descriptions:\n",
    "\n",
    "                            edge_description = \"\\n\".join(\n",
    "                                list(\n",
    "                                    {\n",
    "                                        *unpack_descriptions(edge_data),\n",
    "                                        edge_description,\n",
    "                                    }\n",
    "                                )\n",
    "                            )\n",
    "\n",
    "                        edge_source_id = \", \".join(\n",
    "                            list(\n",
    "                                {\n",
    "                                    *_unpack_source_ids(edge_data),\n",
    "                                    str(source_doc_id),\n",
    "                                }\n",
    "                            )\n",
    "                        )\n",
    "\n",
    "                graph.add_edge(\n",
    "                    source,\n",
    "                    target,\n",
    "                    weight=weight,\n",
    "                    description=edge_description,\n",
    "                    source_id=edge_source_id,\n",
    "                )\n",
    "\n",
    "    return graph\n",
    "\n",
    "\n",
    "DEFAULT_TUPLE_DELIMITER = \"<|>\"\n",
    "DEFAULT_RECORD_DELIMITER = \"##\"\n",
    "DEFAULT_COMPLETION_DELIMITER = \"<|COMPLETE|>\"\n",
    "DEFAULT_ENTITY_TYPES = [\"organization\", \"person\", \"geo\", \"event\"]\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class GraphExtractionResult:\n",
    "    \"\"\"Unipartite graph extraction result class definition.\"\"\"\n",
    "\n",
    "    output: nx.Graph\n",
    "    source_docs: dict[Any, Any]\n",
    "\n",
    "\n",
    "def graph_extractor_forward(\n",
    "    texts: list[str], prompt_variables: dict[str, Any] | None = None\n",
    ") -> GraphExtractionResult:\n",
    "    \"\"\"Call method definition.\"\"\"\n",
    "\n",
    "    if prompt_variables is None:\n",
    "\n",
    "        prompt_variables = {}\n",
    "\n",
    "    all_records: dict[int, str] = {}\n",
    "\n",
    "    source_doc_map: dict[int, str] = {}\n",
    "\n",
    "    # Wire defaults into the prompt variables\n",
    "\n",
    "    prompt_variables = {\n",
    "        **prompt_variables,\n",
    "        tuple_delimiter_key: prompt_variables.get(tuple_delimiter_key)\n",
    "        or DEFAULT_TUPLE_DELIMITER,\n",
    "        record_delimiter_key: prompt_variables.get(record_delimiter_key)\n",
    "        or DEFAULT_RECORD_DELIMITER,\n",
    "        completion_delimiter_key: prompt_variables.get(completion_delimiter_key)\n",
    "        or DEFAULT_COMPLETION_DELIMITER,\n",
    "        entity_types_key: \",\".join(\n",
    "            prompt_variables[entity_types_key] or DEFAULT_ENTITY_TYPES\n",
    "        ),\n",
    "    }\n",
    "\n",
    "    for doc_index, text in enumerate(texts):\n",
    "        # Invoke the entity extraction\n",
    "        result = process_document(\n",
    "            GRAPH_EXTRACTION_PROMPT,\n",
    "            text,\n",
    "            prompt_variables,\n",
    "        )\n",
    "        source_doc_map[doc_index] = text\n",
    "        all_records[doc_index] = result\n",
    "\n",
    "    output = process_results(\n",
    "        all_records,\n",
    "        prompt_variables.get(tuple_delimiter_key, DEFAULT_TUPLE_DELIMITER),\n",
    "        prompt_variables.get(record_delimiter_key, DEFAULT_RECORD_DELIMITER),\n",
    "    )\n",
    "\n",
    "    return GraphExtractionResult(\n",
    "        output=output,\n",
    "        source_docs=source_doc_map,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "from retreivers.radiowiki import RadioWikiRetriever\n",
    "\n",
    "retriever = RadioWikiRetriever()\n",
    "docs = retriever.request(\"atelectasis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_0 = docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class Document:\n",
    "    \"\"\"Document class definition.\"\"\"\n",
    "    text: str\n",
    "    title: str\n",
    "    id: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents.base import Document as LC_doc\n",
    "from typing import List\n",
    "\n",
    "\n",
    "def lc_to_graphrag_doc(lc_docs: List[LC_doc]):\n",
    "    return [\n",
    "        Document(title=d.metadata[\"title\"], text=d.page_content, id=i)\n",
    "        for i, d in enumerate(lc_docs)\n",
    "    ]\n",
    "\n",
    "\n",
    "from collections.abc import Iterable\n",
    "from hashlib import md5\n",
    "from typing import Any\n",
    "\n",
    "# this is how the id is generated.\n",
    "def gen_md5_hash(item: dict[str, Any], hashcode: Iterable[str]):\n",
    "    \"\"\"Generate an md5 hash.\"\"\"\n",
    "    hashed = \"\".join([str(item[column]) for column in hashcode])\n",
    "    return f\"{md5(hashed.encode('utf-8'), usedforsecurity=False).hexdigest()}\n",
    "\n",
    "def lc_doc_to_df(lc_docs: List[LC_doc]) -> pd.DataFrame:\n",
    "    return pd.DataFrame(\n",
    "        [\n",
    "            {\n",
    "                \"id\": gen_md5_hash({'text': d.page_content} ,['text']),\n",
    "                \"text\": d.page_content,\n",
    "                \"title\": d.metadata[\"title\"],\n",
    "            }\n",
    "            for i, d in enumerate(lc_docs)\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_ENTITY_TYPES = [\n",
    "    \"disease\",\n",
    "    \"symptom\",\n",
    "]\n",
    "entity_types = DEFAULT_ENTITY_TYPES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input is created using:\n",
    "@dataclass\n",
    "class EntityExtractionResult:\n",
    "    \"\"\"Entity extraction result class definition.\"\"\"\n",
    "    entities: list[dict[str, Any]]\n",
    "    graphml_graph: str | None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_extract_entities(\n",
    "    row_docs: List[Document],\n",
    "    entity_types: List[str],\n",
    "):\n",
    "    text_list = [doc.text.strip() for doc in row_docs]\n",
    "    text_list = text_splitter.split_text(\"\\n\".join(text_list))\n",
    "    results = graph_extractor_forward(\n",
    "        list(text_list),\n",
    "        {\n",
    "            \"entity_types\": entity_types,\n",
    "        },\n",
    "    )\n",
    "    Debugger.results_in_run_extract = results\n",
    "    \n",
    "    # raise StopIteration()\n",
    "\n",
    "    graph = results.output\n",
    "    # Map the \"source_id\" back to the \"id\" field\n",
    "    for _, node in graph.nodes(data=True):  # type: ignore\n",
    "        if node is not None:\n",
    "            node[\"source_id\"] = \",\".join(\n",
    "                row_docs[int(id)].id for id in node[\"source_id\"].split(\",\")\n",
    "            )\n",
    "    # their documents has ids\n",
    "    for _, _, edge in graph.edges(data=True):  # type: ignore\n",
    "        if edge is not None:\n",
    "            edge[\"source_id\"] = \",\".join(\n",
    "                row_docs[int(id)].id for id in edge[\"source_id\"].split(\",\")\n",
    "            )\n",
    "\n",
    "    entities = [\n",
    "        ({\"name\": item[0], **(item[1] or {})})\n",
    "        for item in graph.nodes(data=True)\n",
    "        if item is not None\n",
    "    ]\n",
    "\n",
    "    graph_data = \"\".join(nx.generate_graphml(graph))\n",
    "    return EntityExtractionResult(entities, graph_data)\n",
    "\n",
    "\n",
    "# @dataclass\n",
    "# class Covariate:\n",
    "#     \"\"\"Covariate class definition.\"\"\"\n",
    "\n",
    "#     covariate_type: str | None = None\n",
    "#     subject_id: str | None = None\n",
    "#     subject_type: str | None = None\n",
    "#     object_id: str | None = None\n",
    "#     object_type: str | None = None\n",
    "#     type: str | None = None\n",
    "#     status: str | None = None\n",
    "#     start_date: str | None = None\n",
    "#     end_date: str | None = None\n",
    "#     description: str | None = None\n",
    "#     source_text: list[str] | None = None\n",
    "#     doc_id: str | None = None\n",
    "#     record_id: int | None = None\n",
    "#     id: str | None = None\n",
    "\n",
    "\n",
    "# from dataclasses import asdict\n",
    "\n",
    "# COVARIATE_TYPE = \"claim\"  # guessing\n",
    "\n",
    "\n",
    "# def create_row_from_claim_data(row, covariate_data: Covariate, covariate_type: str):\n",
    "#     \"\"\"Create a row from the claim data and the input row.\"\"\"\n",
    "#     item = {**row, **asdict(covariate_data), \"covariate_type\": covariate_type}\n",
    "#     # TODO: doc_id from extraction isn't necessary\n",
    "#     # since chunking happens before this\n",
    "#     del item[\"doc_id\"]\n",
    "#     return item\n",
    "\n",
    "\n",
    "def run_strategy(row):\n",
    "    text = row[\"text\"]\n",
    "    id = row[\"id\"]\n",
    "    title = row[\"title\"]\n",
    "    result = run_extract_entities(\n",
    "        [Document(text=text, id=id, title=title)],\n",
    "        entity_types,\n",
    "    )\n",
    "    return [result.entities, result.graphml_graph]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load local text.\n",
    "docs_df = lc_doc_to_df(docs)\n",
    "to = \"to_col\"\n",
    "graph_to = \"graph_to_col\"\n",
    "\n",
    "def workflow_run(docs_df):\n",
    "    to_result = []\n",
    "    graph_to_result = []\n",
    "    output = docs_df # I guess?\n",
    "    results = []\n",
    "\n",
    "    for idx, row in docs_df.iterrows():\n",
    "        result = run_strategy(row)\n",
    "        results.append(result)\n",
    "\n",
    "    for result in results:\n",
    "        if result:\n",
    "            to_result.append(result[0])\n",
    "            graph_to_result.append(result[1])\n",
    "        else:\n",
    "            to_result.append(None)\n",
    "            graph_to_result.append(None)\n",
    "\n",
    "    output[to] = to_result\n",
    "    if graph_to is not None:\n",
    "        output[graph_to] = graph_to_result\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "def join_path(file_path: str, file_name: str) -> Path:\n",
    "    \"\"\"Join a path and a file. Independent of the OS.\"\"\"\n",
    "    return Path(file_path) / Path(file_name).parent / Path(file_name).name\n",
    "\n",
    "def file_storage_set(\n",
    "    file_path: str,\n",
    "    value: Any,\n",
    ") -> None:\n",
    "    \"\"\"Set method definition.\"\"\"\n",
    "    is_bytes = isinstance(value, bytes)\n",
    "    write_type = \"wb\" if is_bytes else \"w\"\n",
    "    encoding = None if is_bytes else \"utf-8\"\n",
    "    with open(file_path, cast(Any, write_type), encoding=encoding) as f:\n",
    "        f.write(value)\n",
    "    \n",
    "def parquet_table_emitter_emit(name: str, data: pd.DataFrame) -> None:\n",
    "    \"\"\"Emit a dataframe to storage.\"\"\"\n",
    "    filename = f\"{name}.parquet\"\n",
    "    file_storage_set(filename, data.to_parquet())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>atelectasis (summary) | radiology reference ar...</td>\n",
       "      <td>Atelectasis (summary) | Radiology Reference Ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>linear atelectasis | radiology reference artic...</td>\n",
       "      <td>Linear atelectasis | Radiology Reference Artic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>lung atelectasis | radiology reference article...</td>\n",
       "      <td>Lung atelectasis | Radiology Reference Article...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>subsegmental atelectasis | radiology reference...</td>\n",
       "      <td>Subsegmental atelectasis | Radiology Reference...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>round atelectasis | radiology reference articl...</td>\n",
       "      <td>Round atelectasis | Radiology Reference Articl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>passive atelectasis | radiology reference arti...</td>\n",
       "      <td>Passive atelectasis | Radiology Reference Arti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>compressive atelectasis | radiology reference ...</td>\n",
       "      <td>Compressive atelectasis | Radiology Reference ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>cicatrisation atelectasis | radiology referenc...</td>\n",
       "      <td>Cicatrisation atelectasis | Radiology Referenc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>segmental atelectasis | radiology reference ar...</td>\n",
       "      <td>Segmental atelectasis | Radiology Reference Ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>adhesive atelectasis | radiology reference art...</td>\n",
       "      <td>Adhesive atelectasis | Radiology Reference Art...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>resorptive (obstructive) atelectasis | radiolo...</td>\n",
       "      <td>Resorptive (obstructive) atelectasis | Radiolo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>chronic maxillary atelectasis | radiology refe...</td>\n",
       "      <td>Chronic maxillary atelectasis | Radiology Refe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>middle ear atelectasis | radiology reference a...</td>\n",
       "      <td>Middle ear atelectasis | Radiology Reference A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>gravity-dependent atelectasis | radiology refe...</td>\n",
       "      <td>Gravity-dependent atelectasis | Radiology Refe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>crow feet sign (round atelectasis) | radiology...</td>\n",
       "      <td>Crow feet sign (round atelectasis) | Radiology...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>osteophyte-induced adjacent pulmonary atelecta...</td>\n",
       "      <td>Osteophyte-induced adjacent pulmonary atelecta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>lobar lung collapse | radiology reference arti...</td>\n",
       "      <td>Lobar lung collapse | Radiology Reference Arti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>right middle lobe collapse | radiology referen...</td>\n",
       "      <td>Right middle lobe collapse | Radiology Referen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>anectasis | radiology reference article | radi...</td>\n",
       "      <td>Anectasis | Radiology Reference Article | Radi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>silent sinus syndrome | radiology reference ar...</td>\n",
       "      <td>Silent sinus syndrome | Radiology Reference Ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>atelectasis is the partial collapse or closure...</td>\n",
       "      <td>Atelectasis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>silent sinus syndrome is a spontaneous, asympt...</td>\n",
       "      <td>Silent sinus syndrome</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>tympanic membrane retraction describes a condi...</td>\n",
       "      <td>Tympanic membrane retraction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>the thorax (pl.: thoraces or thoraxes) or ches...</td>\n",
       "      <td>Thorax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>dornase alfa, sold under the brand name pulmoz...</td>\n",
       "      <td>Dornase alfa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>asbestos-related diseases are disorders of the...</td>\n",
       "      <td>Asbestos-related diseases</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>mediastinal shift is an abnormal movement of t...</td>\n",
       "      <td>Mediastinal shift</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>ventilator-associated lung injury (vali) is an...</td>\n",
       "      <td>Ventilator-associated lung injury</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>respiratory failure results from inadequate ga...</td>\n",
       "      <td>Respiratory failure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>ectasia (), also called ectasis (), is dilatio...</td>\n",
       "      <td>Ectasia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30</td>\n",
       "      <td>oxygen therapy, also referred to as supplement...</td>\n",
       "      <td>Oxygen therapy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31</td>\n",
       "      <td>pulmonary hygiene, also referred to as pulmona...</td>\n",
       "      <td>Pulmonary hygiene</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>32</td>\n",
       "      <td>william pasteur (1855-1943) was a british phys...</td>\n",
       "      <td>William Pasteur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>33</td>\n",
       "      <td>postoperative fever refers to an elevated body...</td>\n",
       "      <td>Postoperative fever</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>34</td>\n",
       "      <td>flat-chested kitten syndrome (fcks) is a disor...</td>\n",
       "      <td>Flat-chested kitten syndrome</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>35</td>\n",
       "      <td>peribronchial cuffing, also referred to as per...</td>\n",
       "      <td>Peribronchial cuffing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>36</td>\n",
       "      <td>intermittent positive pressure breathing (ippb...</td>\n",
       "      <td>Intermittent positive pressure breathing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>37</td>\n",
       "      <td>postpartum infections, also known as childbed ...</td>\n",
       "      <td>Postpartum infections</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>38</td>\n",
       "      <td>pneumothorax ex vacuo is a rare type of pneumo...</td>\n",
       "      <td>Pneumothorax ex vacuo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>39</td>\n",
       "      <td>coronavirus disease 2019 (covid-19) is a conta...</td>\n",
       "      <td>COVID-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>40</td>\n",
       "      <td>a pulmonary alveolus (pl.: alveoli, from latin...</td>\n",
       "      <td>Pulmonary alveolus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>41</td>\n",
       "      <td>crackles are the clicking, rattling, or crackl...</td>\n",
       "      <td>Crackles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>42</td>\n",
       "      <td>prune belly syndrome is a rare, genetic birth ...</td>\n",
       "      <td>Prune belly syndrome</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>43</td>\n",
       "      <td>the comet tail sign is a radiological finding ...</td>\n",
       "      <td>Comet tail sign (CT thorax)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>44</td>\n",
       "      <td>streptococcal pharyngitis, also known as strep...</td>\n",
       "      <td>Streptococcal pharyngitis</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id                                               text  \\\n",
       "0    0  atelectasis (summary) | radiology reference ar...   \n",
       "1    1  linear atelectasis | radiology reference artic...   \n",
       "2    2  lung atelectasis | radiology reference article...   \n",
       "3    3  subsegmental atelectasis | radiology reference...   \n",
       "4    4  round atelectasis | radiology reference articl...   \n",
       "5    5  passive atelectasis | radiology reference arti...   \n",
       "6    6  compressive atelectasis | radiology reference ...   \n",
       "7    7  cicatrisation atelectasis | radiology referenc...   \n",
       "8    8  segmental atelectasis | radiology reference ar...   \n",
       "9    9  adhesive atelectasis | radiology reference art...   \n",
       "10  10  resorptive (obstructive) atelectasis | radiolo...   \n",
       "11  11  chronic maxillary atelectasis | radiology refe...   \n",
       "12  12  middle ear atelectasis | radiology reference a...   \n",
       "13  13  gravity-dependent atelectasis | radiology refe...   \n",
       "14  14  crow feet sign (round atelectasis) | radiology...   \n",
       "15  15  osteophyte-induced adjacent pulmonary atelecta...   \n",
       "16  16  lobar lung collapse | radiology reference arti...   \n",
       "17  17  right middle lobe collapse | radiology referen...   \n",
       "18  18  anectasis | radiology reference article | radi...   \n",
       "19  19  silent sinus syndrome | radiology reference ar...   \n",
       "20  20  atelectasis is the partial collapse or closure...   \n",
       "21  21  silent sinus syndrome is a spontaneous, asympt...   \n",
       "22  22  tympanic membrane retraction describes a condi...   \n",
       "23  23  the thorax (pl.: thoraces or thoraxes) or ches...   \n",
       "24  24  dornase alfa, sold under the brand name pulmoz...   \n",
       "25  25  asbestos-related diseases are disorders of the...   \n",
       "26  26  mediastinal shift is an abnormal movement of t...   \n",
       "27  27  ventilator-associated lung injury (vali) is an...   \n",
       "28  28  respiratory failure results from inadequate ga...   \n",
       "29  29  ectasia (), also called ectasis (), is dilatio...   \n",
       "30  30  oxygen therapy, also referred to as supplement...   \n",
       "31  31  pulmonary hygiene, also referred to as pulmona...   \n",
       "32  32  william pasteur (1855-1943) was a british phys...   \n",
       "33  33  postoperative fever refers to an elevated body...   \n",
       "34  34  flat-chested kitten syndrome (fcks) is a disor...   \n",
       "35  35  peribronchial cuffing, also referred to as per...   \n",
       "36  36  intermittent positive pressure breathing (ippb...   \n",
       "37  37  postpartum infections, also known as childbed ...   \n",
       "38  38  pneumothorax ex vacuo is a rare type of pneumo...   \n",
       "39  39  coronavirus disease 2019 (covid-19) is a conta...   \n",
       "40  40  a pulmonary alveolus (pl.: alveoli, from latin...   \n",
       "41  41  crackles are the clicking, rattling, or crackl...   \n",
       "42  42  prune belly syndrome is a rare, genetic birth ...   \n",
       "43  43  the comet tail sign is a radiological finding ...   \n",
       "44  44  streptococcal pharyngitis, also known as strep...   \n",
       "\n",
       "                                                title  \n",
       "0   Atelectasis (summary) | Radiology Reference Ar...  \n",
       "1   Linear atelectasis | Radiology Reference Artic...  \n",
       "2   Lung atelectasis | Radiology Reference Article...  \n",
       "3   Subsegmental atelectasis | Radiology Reference...  \n",
       "4   Round atelectasis | Radiology Reference Articl...  \n",
       "5   Passive atelectasis | Radiology Reference Arti...  \n",
       "6   Compressive atelectasis | Radiology Reference ...  \n",
       "7   Cicatrisation atelectasis | Radiology Referenc...  \n",
       "8   Segmental atelectasis | Radiology Reference Ar...  \n",
       "9   Adhesive atelectasis | Radiology Reference Art...  \n",
       "10  Resorptive (obstructive) atelectasis | Radiolo...  \n",
       "11  Chronic maxillary atelectasis | Radiology Refe...  \n",
       "12  Middle ear atelectasis | Radiology Reference A...  \n",
       "13  Gravity-dependent atelectasis | Radiology Refe...  \n",
       "14  Crow feet sign (round atelectasis) | Radiology...  \n",
       "15  Osteophyte-induced adjacent pulmonary atelecta...  \n",
       "16  Lobar lung collapse | Radiology Reference Arti...  \n",
       "17  Right middle lobe collapse | Radiology Referen...  \n",
       "18  Anectasis | Radiology Reference Article | Radi...  \n",
       "19  Silent sinus syndrome | Radiology Reference Ar...  \n",
       "20                                        Atelectasis  \n",
       "21                              Silent sinus syndrome  \n",
       "22                       Tympanic membrane retraction  \n",
       "23                                             Thorax  \n",
       "24                                       Dornase alfa  \n",
       "25                          Asbestos-related diseases  \n",
       "26                                  Mediastinal shift  \n",
       "27                  Ventilator-associated lung injury  \n",
       "28                                Respiratory failure  \n",
       "29                                            Ectasia  \n",
       "30                                     Oxygen therapy  \n",
       "31                                  Pulmonary hygiene  \n",
       "32                                    William Pasteur  \n",
       "33                                Postoperative fever  \n",
       "34                       Flat-chested kitten syndrome  \n",
       "35                              Peribronchial cuffing  \n",
       "36           Intermittent positive pressure breathing  \n",
       "37                              Postpartum infections  \n",
       "38                              Pneumothorax ex vacuo  \n",
       "39                                           COVID-19  \n",
       "40                                 Pulmonary alveolus  \n",
       "41                                           Crackles  \n",
       "42                               Prune belly syndrome  \n",
       "43                        Comet tail sign (CT thorax)  \n",
       "44                          Streptococcal pharyngitis  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "sequence item 0: expected str instance, int found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# saving to the paquet?\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m output \u001b[38;5;241m=\u001b[39m workflow_run(docs_df)\n\u001b[0;32m      3\u001b[0m parquet_table_emitter_emit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124matelectasis_idx\u001b[39m\u001b[38;5;124m\"\u001b[39m, output)\n",
      "Cell \u001b[1;32mIn[17], line 13\u001b[0m, in \u001b[0;36mworkflow_run\u001b[1;34m(docs_df)\u001b[0m\n\u001b[0;32m     10\u001b[0m results \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, row \u001b[38;5;129;01min\u001b[39;00m docs_df\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[1;32m---> 13\u001b[0m     result \u001b[38;5;241m=\u001b[39m run_strategy(row)\n\u001b[0;32m     14\u001b[0m     results\u001b[38;5;241m.\u001b[39mappend(result)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m results:\n",
      "Cell \u001b[1;32mIn[16], line 79\u001b[0m, in \u001b[0;36mrun_strategy\u001b[1;34m(row)\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28mid\u001b[39m \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     78\u001b[0m title \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m---> 79\u001b[0m result \u001b[38;5;241m=\u001b[39m run_extract_entities(\n\u001b[0;32m     80\u001b[0m     [Document(text\u001b[38;5;241m=\u001b[39mtext, \u001b[38;5;28mid\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mid\u001b[39m, title\u001b[38;5;241m=\u001b[39mtitle)],\n\u001b[0;32m     81\u001b[0m     entity_types,\n\u001b[0;32m     82\u001b[0m )\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [result\u001b[38;5;241m.\u001b[39mentities, result\u001b[38;5;241m.\u001b[39mgraphml_graph]\n",
      "Cell \u001b[1;32mIn[16], line 21\u001b[0m, in \u001b[0;36mrun_extract_entities\u001b[1;34m(row_docs, entity_types)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, node \u001b[38;5;129;01min\u001b[39;00m graph\u001b[38;5;241m.\u001b[39mnodes(data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m node \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 21\u001b[0m         node[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource_id\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[0;32m     22\u001b[0m             row_docs[\u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mid\u001b[39m)]\u001b[38;5;241m.\u001b[39mid \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mid\u001b[39m \u001b[38;5;129;01min\u001b[39;00m node[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource_id\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     23\u001b[0m         )\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# their documents has ids\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, _, edge \u001b[38;5;129;01min\u001b[39;00m graph\u001b[38;5;241m.\u001b[39medges(data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: sequence item 0: expected str instance, int found"
     ]
    }
   ],
   "source": [
    "# saving to the paquet?\n",
    "output = workflow_run(docs_df)\n",
    "parquet_table_emitter_emit(\"atelectasis_idx\", output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>title</th>\n",
       "      <th>to_col</th>\n",
       "      <th>graph_to_col</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>atelectasis (summary) | radiology reference ar...</td>\n",
       "      <td>Atelectasis (summary) | Radiology Reference Ar...</td>\n",
       "      <td>[]</td>\n",
       "      <td>&lt;graphml xmlns=\"http://graphml.graphdrawing.or...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>linear atelectasis | radiology reference artic...</td>\n",
       "      <td>Linear atelectasis | Radiology Reference Artic...</td>\n",
       "      <td>[]</td>\n",
       "      <td>&lt;graphml xmlns=\"http://graphml.graphdrawing.or...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>lung atelectasis | radiology reference article...</td>\n",
       "      <td>Lung atelectasis | Radiology Reference Article...</td>\n",
       "      <td>[]</td>\n",
       "      <td>&lt;graphml xmlns=\"http://graphml.graphdrawing.or...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>subsegmental atelectasis | radiology reference...</td>\n",
       "      <td>Subsegmental atelectasis | Radiology Reference...</td>\n",
       "      <td>[]</td>\n",
       "      <td>&lt;graphml xmlns=\"http://graphml.graphdrawing.or...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>round atelectasis | radiology reference articl...</td>\n",
       "      <td>Round atelectasis | Radiology Reference Articl...</td>\n",
       "      <td>[]</td>\n",
       "      <td>&lt;graphml xmlns=\"http://graphml.graphdrawing.or...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>passive atelectasis | radiology reference arti...</td>\n",
       "      <td>Passive atelectasis | Radiology Reference Arti...</td>\n",
       "      <td>[]</td>\n",
       "      <td>&lt;graphml xmlns=\"http://graphml.graphdrawing.or...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>compressive atelectasis | radiology reference ...</td>\n",
       "      <td>Compressive atelectasis | Radiology Reference ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>&lt;graphml xmlns=\"http://graphml.graphdrawing.or...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>cicatrisation atelectasis | radiology referenc...</td>\n",
       "      <td>Cicatrisation atelectasis | Radiology Referenc...</td>\n",
       "      <td>[]</td>\n",
       "      <td>&lt;graphml xmlns=\"http://graphml.graphdrawing.or...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>segmental atelectasis | radiology reference ar...</td>\n",
       "      <td>Segmental atelectasis | Radiology Reference Ar...</td>\n",
       "      <td>[]</td>\n",
       "      <td>&lt;graphml xmlns=\"http://graphml.graphdrawing.or...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>adhesive atelectasis | radiology reference art...</td>\n",
       "      <td>Adhesive atelectasis | Radiology Reference Art...</td>\n",
       "      <td>[]</td>\n",
       "      <td>&lt;graphml xmlns=\"http://graphml.graphdrawing.or...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>resorptive (obstructive) atelectasis | radiolo...</td>\n",
       "      <td>Resorptive (obstructive) atelectasis | Radiolo...</td>\n",
       "      <td>[]</td>\n",
       "      <td>&lt;graphml xmlns=\"http://graphml.graphdrawing.or...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>chronic maxillary atelectasis | radiology refe...</td>\n",
       "      <td>Chronic maxillary atelectasis | Radiology Refe...</td>\n",
       "      <td>[]</td>\n",
       "      <td>&lt;graphml xmlns=\"http://graphml.graphdrawing.or...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>middle ear atelectasis | radiology reference a...</td>\n",
       "      <td>Middle ear atelectasis | Radiology Reference A...</td>\n",
       "      <td>[]</td>\n",
       "      <td>&lt;graphml xmlns=\"http://graphml.graphdrawing.or...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>gravity-dependent atelectasis | radiology refe...</td>\n",
       "      <td>Gravity-dependent atelectasis | Radiology Refe...</td>\n",
       "      <td>[]</td>\n",
       "      <td>&lt;graphml xmlns=\"http://graphml.graphdrawing.or...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>crow feet sign (round atelectasis) | radiology...</td>\n",
       "      <td>Crow feet sign (round atelectasis) | Radiology...</td>\n",
       "      <td>[]</td>\n",
       "      <td>&lt;graphml xmlns=\"http://graphml.graphdrawing.or...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>osteophyte-induced adjacent pulmonary atelecta...</td>\n",
       "      <td>Osteophyte-induced adjacent pulmonary atelecta...</td>\n",
       "      <td>[]</td>\n",
       "      <td>&lt;graphml xmlns=\"http://graphml.graphdrawing.or...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>lobar lung collapse | radiology reference arti...</td>\n",
       "      <td>Lobar lung collapse | Radiology Reference Arti...</td>\n",
       "      <td>[]</td>\n",
       "      <td>&lt;graphml xmlns=\"http://graphml.graphdrawing.or...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>right middle lobe collapse | radiology referen...</td>\n",
       "      <td>Right middle lobe collapse | Radiology Referen...</td>\n",
       "      <td>[]</td>\n",
       "      <td>&lt;graphml xmlns=\"http://graphml.graphdrawing.or...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>anectasis | radiology reference article | radi...</td>\n",
       "      <td>Anectasis | Radiology Reference Article | Radi...</td>\n",
       "      <td>[]</td>\n",
       "      <td>&lt;graphml xmlns=\"http://graphml.graphdrawing.or...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>silent sinus syndrome | radiology reference ar...</td>\n",
       "      <td>Silent sinus syndrome | Radiology Reference Ar...</td>\n",
       "      <td>[]</td>\n",
       "      <td>&lt;graphml xmlns=\"http://graphml.graphdrawing.or...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>atelectasis is the partial collapse or closure...</td>\n",
       "      <td>Atelectasis</td>\n",
       "      <td>[]</td>\n",
       "      <td>&lt;graphml xmlns=\"http://graphml.graphdrawing.or...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>silent sinus syndrome is a spontaneous, asympt...</td>\n",
       "      <td>Silent sinus syndrome</td>\n",
       "      <td>[]</td>\n",
       "      <td>&lt;graphml xmlns=\"http://graphml.graphdrawing.or...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>tympanic membrane retraction describes a condi...</td>\n",
       "      <td>Tympanic membrane retraction</td>\n",
       "      <td>[]</td>\n",
       "      <td>&lt;graphml xmlns=\"http://graphml.graphdrawing.or...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>the thorax (pl.: thoraces or thoraxes) or ches...</td>\n",
       "      <td>Thorax</td>\n",
       "      <td>[]</td>\n",
       "      <td>&lt;graphml xmlns=\"http://graphml.graphdrawing.or...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>dornase alfa, sold under the brand name pulmoz...</td>\n",
       "      <td>Dornase alfa</td>\n",
       "      <td>[]</td>\n",
       "      <td>&lt;graphml xmlns=\"http://graphml.graphdrawing.or...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>asbestos-related diseases are disorders of the...</td>\n",
       "      <td>Asbestos-related diseases</td>\n",
       "      <td>[]</td>\n",
       "      <td>&lt;graphml xmlns=\"http://graphml.graphdrawing.or...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>mediastinal shift is an abnormal movement of t...</td>\n",
       "      <td>Mediastinal shift</td>\n",
       "      <td>[]</td>\n",
       "      <td>&lt;graphml xmlns=\"http://graphml.graphdrawing.or...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>ventilator-associated lung injury (vali) is an...</td>\n",
       "      <td>Ventilator-associated lung injury</td>\n",
       "      <td>[]</td>\n",
       "      <td>&lt;graphml xmlns=\"http://graphml.graphdrawing.or...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>respiratory failure results from inadequate ga...</td>\n",
       "      <td>Respiratory failure</td>\n",
       "      <td>[]</td>\n",
       "      <td>&lt;graphml xmlns=\"http://graphml.graphdrawing.or...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>ectasia (), also called ectasis (), is dilatio...</td>\n",
       "      <td>Ectasia</td>\n",
       "      <td>[]</td>\n",
       "      <td>&lt;graphml xmlns=\"http://graphml.graphdrawing.or...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30</td>\n",
       "      <td>oxygen therapy, also referred to as supplement...</td>\n",
       "      <td>Oxygen therapy</td>\n",
       "      <td>[]</td>\n",
       "      <td>&lt;graphml xmlns=\"http://graphml.graphdrawing.or...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31</td>\n",
       "      <td>pulmonary hygiene, also referred to as pulmona...</td>\n",
       "      <td>Pulmonary hygiene</td>\n",
       "      <td>[]</td>\n",
       "      <td>&lt;graphml xmlns=\"http://graphml.graphdrawing.or...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>32</td>\n",
       "      <td>william pasteur (1855-1943) was a british phys...</td>\n",
       "      <td>William Pasteur</td>\n",
       "      <td>[]</td>\n",
       "      <td>&lt;graphml xmlns=\"http://graphml.graphdrawing.or...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>33</td>\n",
       "      <td>postoperative fever refers to an elevated body...</td>\n",
       "      <td>Postoperative fever</td>\n",
       "      <td>[]</td>\n",
       "      <td>&lt;graphml xmlns=\"http://graphml.graphdrawing.or...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>34</td>\n",
       "      <td>flat-chested kitten syndrome (fcks) is a disor...</td>\n",
       "      <td>Flat-chested kitten syndrome</td>\n",
       "      <td>[]</td>\n",
       "      <td>&lt;graphml xmlns=\"http://graphml.graphdrawing.or...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>35</td>\n",
       "      <td>peribronchial cuffing, also referred to as per...</td>\n",
       "      <td>Peribronchial cuffing</td>\n",
       "      <td>[]</td>\n",
       "      <td>&lt;graphml xmlns=\"http://graphml.graphdrawing.or...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>36</td>\n",
       "      <td>intermittent positive pressure breathing (ippb...</td>\n",
       "      <td>Intermittent positive pressure breathing</td>\n",
       "      <td>[]</td>\n",
       "      <td>&lt;graphml xmlns=\"http://graphml.graphdrawing.or...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>37</td>\n",
       "      <td>postpartum infections, also known as childbed ...</td>\n",
       "      <td>Postpartum infections</td>\n",
       "      <td>[]</td>\n",
       "      <td>&lt;graphml xmlns=\"http://graphml.graphdrawing.or...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>38</td>\n",
       "      <td>pneumothorax ex vacuo is a rare type of pneumo...</td>\n",
       "      <td>Pneumothorax ex vacuo</td>\n",
       "      <td>[]</td>\n",
       "      <td>&lt;graphml xmlns=\"http://graphml.graphdrawing.or...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>39</td>\n",
       "      <td>coronavirus disease 2019 (covid-19) is a conta...</td>\n",
       "      <td>COVID-19</td>\n",
       "      <td>[]</td>\n",
       "      <td>&lt;graphml xmlns=\"http://graphml.graphdrawing.or...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>40</td>\n",
       "      <td>a pulmonary alveolus (pl.: alveoli, from latin...</td>\n",
       "      <td>Pulmonary alveolus</td>\n",
       "      <td>[]</td>\n",
       "      <td>&lt;graphml xmlns=\"http://graphml.graphdrawing.or...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>41</td>\n",
       "      <td>crackles are the clicking, rattling, or crackl...</td>\n",
       "      <td>Crackles</td>\n",
       "      <td>[]</td>\n",
       "      <td>&lt;graphml xmlns=\"http://graphml.graphdrawing.or...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>42</td>\n",
       "      <td>prune belly syndrome is a rare, genetic birth ...</td>\n",
       "      <td>Prune belly syndrome</td>\n",
       "      <td>[]</td>\n",
       "      <td>&lt;graphml xmlns=\"http://graphml.graphdrawing.or...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>43</td>\n",
       "      <td>the comet tail sign is a radiological finding ...</td>\n",
       "      <td>Comet tail sign (CT thorax)</td>\n",
       "      <td>[]</td>\n",
       "      <td>&lt;graphml xmlns=\"http://graphml.graphdrawing.or...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>44</td>\n",
       "      <td>streptococcal pharyngitis, also known as strep...</td>\n",
       "      <td>Streptococcal pharyngitis</td>\n",
       "      <td>[]</td>\n",
       "      <td>&lt;graphml xmlns=\"http://graphml.graphdrawing.or...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id                                               text  \\\n",
       "0    0  atelectasis (summary) | radiology reference ar...   \n",
       "1    1  linear atelectasis | radiology reference artic...   \n",
       "2    2  lung atelectasis | radiology reference article...   \n",
       "3    3  subsegmental atelectasis | radiology reference...   \n",
       "4    4  round atelectasis | radiology reference articl...   \n",
       "5    5  passive atelectasis | radiology reference arti...   \n",
       "6    6  compressive atelectasis | radiology reference ...   \n",
       "7    7  cicatrisation atelectasis | radiology referenc...   \n",
       "8    8  segmental atelectasis | radiology reference ar...   \n",
       "9    9  adhesive atelectasis | radiology reference art...   \n",
       "10  10  resorptive (obstructive) atelectasis | radiolo...   \n",
       "11  11  chronic maxillary atelectasis | radiology refe...   \n",
       "12  12  middle ear atelectasis | radiology reference a...   \n",
       "13  13  gravity-dependent atelectasis | radiology refe...   \n",
       "14  14  crow feet sign (round atelectasis) | radiology...   \n",
       "15  15  osteophyte-induced adjacent pulmonary atelecta...   \n",
       "16  16  lobar lung collapse | radiology reference arti...   \n",
       "17  17  right middle lobe collapse | radiology referen...   \n",
       "18  18  anectasis | radiology reference article | radi...   \n",
       "19  19  silent sinus syndrome | radiology reference ar...   \n",
       "20  20  atelectasis is the partial collapse or closure...   \n",
       "21  21  silent sinus syndrome is a spontaneous, asympt...   \n",
       "22  22  tympanic membrane retraction describes a condi...   \n",
       "23  23  the thorax (pl.: thoraces or thoraxes) or ches...   \n",
       "24  24  dornase alfa, sold under the brand name pulmoz...   \n",
       "25  25  asbestos-related diseases are disorders of the...   \n",
       "26  26  mediastinal shift is an abnormal movement of t...   \n",
       "27  27  ventilator-associated lung injury (vali) is an...   \n",
       "28  28  respiratory failure results from inadequate ga...   \n",
       "29  29  ectasia (), also called ectasis (), is dilatio...   \n",
       "30  30  oxygen therapy, also referred to as supplement...   \n",
       "31  31  pulmonary hygiene, also referred to as pulmona...   \n",
       "32  32  william pasteur (1855-1943) was a british phys...   \n",
       "33  33  postoperative fever refers to an elevated body...   \n",
       "34  34  flat-chested kitten syndrome (fcks) is a disor...   \n",
       "35  35  peribronchial cuffing, also referred to as per...   \n",
       "36  36  intermittent positive pressure breathing (ippb...   \n",
       "37  37  postpartum infections, also known as childbed ...   \n",
       "38  38  pneumothorax ex vacuo is a rare type of pneumo...   \n",
       "39  39  coronavirus disease 2019 (covid-19) is a conta...   \n",
       "40  40  a pulmonary alveolus (pl.: alveoli, from latin...   \n",
       "41  41  crackles are the clicking, rattling, or crackl...   \n",
       "42  42  prune belly syndrome is a rare, genetic birth ...   \n",
       "43  43  the comet tail sign is a radiological finding ...   \n",
       "44  44  streptococcal pharyngitis, also known as strep...   \n",
       "\n",
       "                                                title to_col  \\\n",
       "0   Atelectasis (summary) | Radiology Reference Ar...     []   \n",
       "1   Linear atelectasis | Radiology Reference Artic...     []   \n",
       "2   Lung atelectasis | Radiology Reference Article...     []   \n",
       "3   Subsegmental atelectasis | Radiology Reference...     []   \n",
       "4   Round atelectasis | Radiology Reference Articl...     []   \n",
       "5   Passive atelectasis | Radiology Reference Arti...     []   \n",
       "6   Compressive atelectasis | Radiology Reference ...     []   \n",
       "7   Cicatrisation atelectasis | Radiology Referenc...     []   \n",
       "8   Segmental atelectasis | Radiology Reference Ar...     []   \n",
       "9   Adhesive atelectasis | Radiology Reference Art...     []   \n",
       "10  Resorptive (obstructive) atelectasis | Radiolo...     []   \n",
       "11  Chronic maxillary atelectasis | Radiology Refe...     []   \n",
       "12  Middle ear atelectasis | Radiology Reference A...     []   \n",
       "13  Gravity-dependent atelectasis | Radiology Refe...     []   \n",
       "14  Crow feet sign (round atelectasis) | Radiology...     []   \n",
       "15  Osteophyte-induced adjacent pulmonary atelecta...     []   \n",
       "16  Lobar lung collapse | Radiology Reference Arti...     []   \n",
       "17  Right middle lobe collapse | Radiology Referen...     []   \n",
       "18  Anectasis | Radiology Reference Article | Radi...     []   \n",
       "19  Silent sinus syndrome | Radiology Reference Ar...     []   \n",
       "20                                        Atelectasis     []   \n",
       "21                              Silent sinus syndrome     []   \n",
       "22                       Tympanic membrane retraction     []   \n",
       "23                                             Thorax     []   \n",
       "24                                       Dornase alfa     []   \n",
       "25                          Asbestos-related diseases     []   \n",
       "26                                  Mediastinal shift     []   \n",
       "27                  Ventilator-associated lung injury     []   \n",
       "28                                Respiratory failure     []   \n",
       "29                                            Ectasia     []   \n",
       "30                                     Oxygen therapy     []   \n",
       "31                                  Pulmonary hygiene     []   \n",
       "32                                    William Pasteur     []   \n",
       "33                                Postoperative fever     []   \n",
       "34                       Flat-chested kitten syndrome     []   \n",
       "35                              Peribronchial cuffing     []   \n",
       "36           Intermittent positive pressure breathing     []   \n",
       "37                              Postpartum infections     []   \n",
       "38                              Pneumothorax ex vacuo     []   \n",
       "39                                           COVID-19     []   \n",
       "40                                 Pulmonary alveolus     []   \n",
       "41                                           Crackles     []   \n",
       "42                               Prune belly syndrome     []   \n",
       "43                        Comet tail sign (CT thorax)     []   \n",
       "44                          Streptococcal pharyngitis     []   \n",
       "\n",
       "                                         graph_to_col  \n",
       "0   <graphml xmlns=\"http://graphml.graphdrawing.or...  \n",
       "1   <graphml xmlns=\"http://graphml.graphdrawing.or...  \n",
       "2   <graphml xmlns=\"http://graphml.graphdrawing.or...  \n",
       "3   <graphml xmlns=\"http://graphml.graphdrawing.or...  \n",
       "4   <graphml xmlns=\"http://graphml.graphdrawing.or...  \n",
       "5   <graphml xmlns=\"http://graphml.graphdrawing.or...  \n",
       "6   <graphml xmlns=\"http://graphml.graphdrawing.or...  \n",
       "7   <graphml xmlns=\"http://graphml.graphdrawing.or...  \n",
       "8   <graphml xmlns=\"http://graphml.graphdrawing.or...  \n",
       "9   <graphml xmlns=\"http://graphml.graphdrawing.or...  \n",
       "10  <graphml xmlns=\"http://graphml.graphdrawing.or...  \n",
       "11  <graphml xmlns=\"http://graphml.graphdrawing.or...  \n",
       "12  <graphml xmlns=\"http://graphml.graphdrawing.or...  \n",
       "13  <graphml xmlns=\"http://graphml.graphdrawing.or...  \n",
       "14  <graphml xmlns=\"http://graphml.graphdrawing.or...  \n",
       "15  <graphml xmlns=\"http://graphml.graphdrawing.or...  \n",
       "16  <graphml xmlns=\"http://graphml.graphdrawing.or...  \n",
       "17  <graphml xmlns=\"http://graphml.graphdrawing.or...  \n",
       "18  <graphml xmlns=\"http://graphml.graphdrawing.or...  \n",
       "19  <graphml xmlns=\"http://graphml.graphdrawing.or...  \n",
       "20  <graphml xmlns=\"http://graphml.graphdrawing.or...  \n",
       "21  <graphml xmlns=\"http://graphml.graphdrawing.or...  \n",
       "22  <graphml xmlns=\"http://graphml.graphdrawing.or...  \n",
       "23  <graphml xmlns=\"http://graphml.graphdrawing.or...  \n",
       "24  <graphml xmlns=\"http://graphml.graphdrawing.or...  \n",
       "25  <graphml xmlns=\"http://graphml.graphdrawing.or...  \n",
       "26  <graphml xmlns=\"http://graphml.graphdrawing.or...  \n",
       "27  <graphml xmlns=\"http://graphml.graphdrawing.or...  \n",
       "28  <graphml xmlns=\"http://graphml.graphdrawing.or...  \n",
       "29  <graphml xmlns=\"http://graphml.graphdrawing.or...  \n",
       "30  <graphml xmlns=\"http://graphml.graphdrawing.or...  \n",
       "31  <graphml xmlns=\"http://graphml.graphdrawing.or...  \n",
       "32  <graphml xmlns=\"http://graphml.graphdrawing.or...  \n",
       "33  <graphml xmlns=\"http://graphml.graphdrawing.or...  \n",
       "34  <graphml xmlns=\"http://graphml.graphdrawing.or...  \n",
       "35  <graphml xmlns=\"http://graphml.graphdrawing.or...  \n",
       "36  <graphml xmlns=\"http://graphml.graphdrawing.or...  \n",
       "37  <graphml xmlns=\"http://graphml.graphdrawing.or...  \n",
       "38  <graphml xmlns=\"http://graphml.graphdrawing.or...  \n",
       "39  <graphml xmlns=\"http://graphml.graphdrawing.or...  \n",
       "40  <graphml xmlns=\"http://graphml.graphdrawing.or...  \n",
       "41  <graphml xmlns=\"http://graphml.graphdrawing.or...  \n",
       "42  <graphml xmlns=\"http://graphml.graphdrawing.or...  \n",
       "43  <graphml xmlns=\"http://graphml.graphdrawing.or...  \n",
       "44  <graphml xmlns=\"http://graphml.graphdrawing.or...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all the results from each row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    " # need to map the graph_data to results here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
